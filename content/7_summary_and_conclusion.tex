\chapter{Summary and Conclusion}\label{ch:summary-and-conclusion}

In this thesis, a neural approach for abstractive meeting summarization was presented.
Segmenting meeting transcripts by topics and generating a summary sentence for each of these segments proved to be a practicable solution to address the usually very long transcripts of meetings.
It was possible to generate meeting transcripts with a modest maximum sequence length of 96 using only a single GeForce RTX 2080 Ti GPU with 11GB of video memory.
The achieved ROUGE-1 scores of the presented neural approach are similar to and the achieved ROUGE-2 scores higher than any of the recent unsupervised approaches for generating abstractive summaries of meetings.
However, these results are not comparable because the neural network has an unfair advantage by having access to the summaries of the training set, while the unsupervised approaches only have the transcripts of the meetings.
To still have a baseline that can be used to validate the results, for each topic of a meeting in the test set, a random summary sentence from the training set was used.
The trained neural network achieved results that are significantly better than this simple baseline, which indicates that a neural data-driven approach seems to work.

Nonetheless, the generated summaries have several issues that make them hardly usable for practical applications.
For instance, summaries often contain duplicate or very similar sentences.
While this issue can be solved quite easily, the more significant problem involves wrong summary sentences that contain incorrect information that is not present in the input.
Additionally, cross-corpus validation and tests on the more diversified ICSI Meeting Corpus show very poor results, which indicates that utilizing transfer learning cannot compensate for the small amount of available training data.

% TODO The last line of a thesis looks to the future positively.