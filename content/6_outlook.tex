\chapter{Outlook}\label{ch:outlook}

During the creation of this thesis, many new language models inspired by BERT have been released, like ALBERT \cite{1909.11942}, RoBERTa \cite{1907.11692} and many more.
These models claim to either achieve better results, have smaller model sizes or both.
It might be worth to investigate, if swapping out BERT with one of these newer models improves the results and if yes by how much.
Additionally, the larger BERT\textsubscript{LARGE} model should be tested, as due to memory constrains only the smaller BERT\textsubscript{BASE} model was used in this work.
This can either be achieved by using hardware with more memory like Google's Cloud TPUs or implementing multi-GPU support.
While multiple GPUs were not supported by BERT originally, there have been many successful attempts that use Uber's Horovod \cite{sergeev2018horovod} utilize multiple GPUs.

% TODO Another topic for future reasearch: Find a way to use speaker information

To build a real end-to-end meeting summarizer, it is also necessary to automatically split a meeting transcript by topics.
The current topic split of AMI used in this work was created manually.
Fortunately, plenty research on automatic topic segmentation has been conducted like \cite{10.3115/1075096.1075167} which specifically focuses on meetings.
Such a topic segmentation algorithm can easily be applied to this work.